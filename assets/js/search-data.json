{
  
    
        "post0": {
            "title": "How to smoothen noisy data and find peaks and dips in a line plot using Python",
            "content": "Presenting peaks and dips in a noisy line plot can be a bit of a challenge, as there is a lot of unnecessary visual information. Savitzky-Golay filter is a function that can be applied to such data in order to clarify the points with minimal distortion and precision loss. It was formulated for the exact purpose of finding maxima and minima in curve data by Savitzky themselves 1. In this small tutorial we will use the U.S. COVID-19 inoculation data to demonstrate the effect of the filter and find the most prominent peaks and dips in daily vaccinations. We will use an interactive widget to tweak the optimal parameters for the filter (click one of the above links for an interactive version). . Step 1: Install the following Python packages . !pip install widgetsnbextension ipywidgets jupyter-js-widgets-nbextension ipympl . Step 2: Enable widget support in your Jupyter environment . !jupyter nbextension enable --py widgetsnbextension --sys-prefix . Enabling notebook extension jupyter-js-widgets/extension... - Validating: OK . Step 3: Importing the dependencies . We will use Pandas to read and manipulate the .csv file, Matplotlib for plotting the data, signal method from the Scipy package to apply the filter, Numpy and argrelextrema function to find the &quot;extreme&quot; values in the data, and finally interactive to build the necessary sliders. . from ipywidgets import interactive import pandas as pd import matplotlib.pyplot as plt from scipy import signal import numpy as np . Step 4: Import and filter the data by location; we will use a CSV file from Our World in Data. . df_raw = pd.read_csv(&quot;https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv&quot;, usecols=[&quot;location&quot;, &quot;date&quot;, &quot;daily_vaccinations&quot;], parse_dates=[&quot;date&quot;]) df = df_raw[df_raw[&quot;location&quot;] == &quot;United States&quot;] df.set_index(&quot;location&quot;, inplace=True, drop=True) df . date daily_vaccinations . location . United States 2020-12-13 | NaN | . United States 2020-12-14 | 4545.0 | . United States 2020-12-15 | 27098.0 | . United States 2020-12-16 | 71299.0 | . United States 2020-12-17 | 121556.0 | . ... ... | ... | . United States 2022-02-25 | 279746.0 | . United States 2022-02-26 | 271896.0 | . United States 2022-02-27 | 260524.0 | . United States 2022-02-28 | 222105.0 | . United States 2022-03-01 | 176778.0 | . 444 rows × 2 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Step 5: Build the function and plot the data . First, we assign our X and Y values. We feed the Y values, or the first 444 consecutive days of daily_vaccinations, into signal.savgol_filter() method. This function requires 2 parameters: windows_size and polyorder. According to the documentation, windows_size is always a positive odd integer and polyorder is any positive integer that is less than window_length 2. Unfortunately my understanding of the concept is very limited, but the general goal is to &quot;[keep] the important features and getting rid of the meaningless fluctuations&quot; 3. These variables control the smoothness of the curve: too low and the curve will lose the detail, too high -- it will become distorted; the rule of thumb is to start low and build up from that. Because the exact values vary with data, they cannot be known beforehand. Controlling them visually will help us find the optimal curve for our purpose, hence the need for a slider to set the inputs more intuitively. . def make_iplot(window_size, polyorder): data_x = df[&quot;date&quot;].values data_y = df[&quot;daily_vaccinations&quot;].values # original data_y_filtered = signal.savgol_filter(data_y, window_size, polyorder) # smoothed # Find peaks (np.greater) peak_indexes = signal.argrelextrema(data_y_filtered, np.greater) peak_indexes = peak_indexes[0] # Find valleys (np.less) valley_indexes = signal.argrelextrema(data_y_filtered, np.less) valley_indexes = valley_indexes[0] # Matplotlib plot plt.figure(figsize=(20, 5)) plt.plot(data_x, data_y, color=&quot;grey&quot;) # line plot for the original data plt.plot(data_x, data_y_filtered, color=&quot;black&quot;) # line plot for the filtered data plt.plot(data_x[valley_indexes], data_y_filtered[valley_indexes], &quot;o&quot;, label=&quot;dip&quot;, color=&quot;r&quot;) plt.plot(data_x[peak_indexes], data_y_filtered[peak_indexes], &quot;o&quot;, label=&quot;peak&quot;, color=&quot;g&quot;) plt.show() . With that said, we arbitrarily set the range of 1 to 100 for the windows_size slider, and 1 to 10 for the polyorder. . %matplotlib inline iplot = interactive( make_iplot, window_size=(1,100,2), polyorder=(1,10,1) ) iplot . . Setting the initial values of 3 and 1 (polyorder &lt; windows_size) as starting points gives us a result that isn&#39;t dissimilar to the original data (red dots represent dips and green ones -- peaks). . %matplotlib inline iplot = interactive( make_iplot, window_size=(1,100,2), polyorder=(1,10,1) ) iplot . . With some experimentation, values 23 and 3 give us a relatively smooth graph with less visual noise. . Conclusion . Applying the Savitzky-Golay filter helps get rid of noise and present a better picture of the data. This may not be the best example, as it doesn&#39;t fluctuate as much as other linear data, such as digital signals, however it can be applied to finding prominent features in any type of data. . 1. Savitzky–Golay filter↩ . 2. scipy.signal.savgol_filter↩ . 3. Smoothing Your Data with the Savitzky-Golay Filter and Python↩ .",
            "url": "https://sergeyyurkov1.github.io/blog/python/jupyter/2022/03/02/Savitzky_Golay_Filter.html",
            "relUrl": "/python/jupyter/2022/03/02/Savitzky_Golay_Filter.html",
            "date": " • Mar 2, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "PhD student in Media and Culture Industry at Soochow University, China. Experienced researcher in media and culture. Skilled in data analysis, software, programming, and academic writing. Master of Journalism and Communication focusing on the negative side of media use. .",
          "url": "https://sergeyyurkov1.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sergeyyurkov1.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}